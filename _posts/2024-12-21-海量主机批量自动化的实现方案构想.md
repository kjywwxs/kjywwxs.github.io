---
categories: 测试
tags: 自动化
---


## 前言

最近遇到了海量主机批量操作的需求，
很简单易想的一个方案是：

- 有一个集中的控制端，它通过建立远程ssh会话到所有在主机上，执行命令，并收集命令的回显，具体的实现可以借助expect（linux中）等,或者自己编写脚本实现远程登陆执行命令等
  
> 这个方案在实施的时候发现了一些问题，如果控制端不需要保持绘画，仅仅是下发命令收集回显，那大部分情况下，可以控制的主机规模能到达**k级别**，如果控制端需要保持会话，时不时发送命令查看某个任务的进展，那么能控制的主机数量会急剧下降
> **总结：这种方案最终都会受限于控制端的性能瓶颈**

## 优化的方案

有没有办法吧负载打散到各个主机上？

优化版的方案借助了网络共享的能力，来将命令的执行动作下放到各个主机上

### 前提条件

- 所有主机挂载，并且可以访问同一个网络文件系统
- 所有主机上运行某个脚本，脚本的功能是监视网络文件系统中某几个文件的变化，来执行对应的行为

脚本具体的功能如下
1.读取共享中的 client_csv配置文件获取所有主机的信息，
2.读取本机获取当前运行的主机的一些信息，和第一个结合获得当前的主机id
3.每隔一段时间就会读取共享中的一个命令配置文件，根据命令的内容，传入主机id参数执行不同的脚本，具体的脚本会将日志输出到共享下的log目录中，以主机id来作为日志文件名

找ai生成的伪代码让如下：

```py
# 导入必要的模块
import os
import csv
import time
import subprocess

# 定义常量
CONFIG_FILE_PATH = "/path/to/shared/client_csv"  # 配置文件路径
COMMAND_FILE_PATH = "/path/to/shared/command_config"  # 命令配置文件路径
LOG_DIR = "/path/to/shared/log"  # 日志目录

def read_config(file_path):
    """读取配置文件并返回数据"""
    data = []
    with open(file_path, mode='r', newline='') as file:
        reader = csv.DictReader(file)
        for row in reader:
            data.append(row)
    return data

def get_local_host_info():
    """获取当前运行主机的信息"""
    # 假设通过某种方式获取当前主机的信息，例如通过环境变量或系统命令
    local_info = {
        # 示例信息，实际根据需求获取
        "host_name": "localhost",
        "host_ip": "127.0.0.1",
        # 其他信息...
    }
    return local_info

def get_current_host_id(client_data, local_info):
    """结合配置文件和本地信息获取当前主机ID"""
    for client in client_data:
        if client["host_name"] == local_info["host_name"] and client["host_ip"] == local_info["host_ip"]:
            return client["host_id"]
    return None

def execute_script(command, host_id):
    """根据命令执行对应的脚本，并输出日志"""
    log_file = os.path.join(LOG_DIR, f"{host_id}.log")
    with open(log_file, 'a') as log:
        try:
            result = subprocess.run(command, shell=True, check=True, stdout=log, stderr=log, text=True)
            log.write(f"Command '{command}' executed successfully.\n")
        except subprocess.CalledProcessError as e:
            log.write(f"Error executing command '{command}': {e}\n")

def monitor_files():
    """监视文件变化并执行对应行为"""
    client_data = read_config(CONFIG_FILE_PATH)
    local_info = get_local_host_info()
    current_host_id = get_current_host_id(client_data, local_info)

    if current_host_id is None:
        print("Current host not found in configuration.")
        return

    while True:
        try:
            # 如果文件没变更就跳过
            if not m_time_change(COMMAND_FILE_PATH):
                continue
            command_data = read_config(COMMAND_FILE_PATH)
            for command_item in command_data:
                command = command_item["command"].format(host_id=current_host_id)
                execute_script(command, current_host_id)

            # 等待一段时间后再读取命令配置文件
            time.sleep(1)  # 例如，每隔60秒检查一次
        except Exception as e:
            print(f"Error monitoring files: {e}")
            time.sleep(10)  # 出现错误时，稍等片刻再重试

if __name__ == "__main__":
    monitor_files()

```

### 具体的命令脚本

具体的命令脚本就是每个主机的操作，可以编写成任意的可执行脚本，放到共享目录下

### 运行

1. 编写好具体的命令脚本，放入指定的共享目录中
2. 编写COMMAND_FILE_PATH配置文件，将每个主机上要执行的命令放入
3. 接下来所有主机会检查到配置文件变化，执行对应的命令脚本，并将日志地呼出在共享中~

## 拓展

### 不同主机有不同的操作的场景

其实上文已经实现按照id识别主机的方式，一种具体可选形式如下

1. 核心就是共享中放一个包含所有主机的配置文件
2. 然后主机上的脚本获得自己的id
3. 主机脚本根据自己的id进行不同的操作

### 不同主机的操作有时序要求的场景

这里提供一个思路

1. 共享内放置文件，内容包含主机id以及命令，按照一行行顺序威力
2. 主机上的脚本会检查文件的第一行，看id是否轮到自己执行
3. 主机脚本如果发现轮到自己执行，就给文件加独占锁，然后执行自己的命令，执行完后，移除文件第一行，释放锁
